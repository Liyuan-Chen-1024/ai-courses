{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements:\n",
    "\n",
    "Your task is to implement a simplified version of an in-memory database. Plan your design according\n",
    "to the level specifications below:\n",
    "- Level 1: In-memory database should support basic operations to manipulate records,\n",
    "fields, and values within fields.\n",
    "- Level 2: In-memory database should support displaying a specific record's fields based on a\n",
    "filter.\n",
    "- Level 3: In-memory database should support TTL (Time-To-Live) configurations on database\n",
    "records.\n",
    "- Level 4: In-memory database should support backup and restore functionality.\n",
    "To move to the next level, you need to pass all the tests at this level.\n",
    "\n",
    "Note:\n",
    "\n",
    "You will receive a list of queries to the system, and the final output should be an array of strings\n",
    "representing the returned values of all queries. Each query will only call one operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 1\n",
    "\n",
    "The basic level of the in-memory database contains records. Each record can be accessed with a\n",
    "unique identifier key of string type. A record may contain several field-value pairs, both of which\n",
    "are of string type.\n",
    "\n",
    "- `SET <key> <field> <value>` — should insert a field-value pair to the record associated\n",
    "with key. If the field in the record already exists, replace the existing value with the\n",
    "specified value. If the record does not exist, create a new one. This operation should return\n",
    "an empty string.\n",
    "\n",
    "- `GET <key> <field>` — should return the value contained within field of the record\n",
    "associated with key. If the record or the field doesn't exist, should return an empty string.\n",
    "\n",
    "- `DELETE <key> <field>` — should remove the field from the record associated with key.\n",
    "Returns \"true\" if the field was successfully deleted, and \"false\" if the key or the field do\n",
    "not exist in the database.\n",
    "\n",
    "\n",
    "Examples\n",
    "\n",
    "The example below shows how these operations should work (the section is scrollable to the right):\n",
    "\n",
    "| Queries | Explanations |\n",
    "|---------|--------------|\n",
    "| `[\"SET\", \"A\", \"B\", \"E\"]` | returns \"\"; database state: `{\"A\": {\"B\": \"E\"}}` |\n",
    "| `[\"SET\", \"A\", \"C\", \"F\"]` | returns \"\"; database state: `{\"A\": {\"C\": \"F\", \"B\": \"E\"}}` |\n",
    "| `[\"GET\", \"A\", \"B\"]` | returns \"E\" |\n",
    "| `[\"GET\", \"A\", \"D\"]` | returns \"\" |\n",
    "| `[\"DELETE\", \"A\", \"B\"]` | returns \"true\"; database state: `{\"A\": {\"C\": \"F\"}}` |\n",
    "| `[\"DELETE\", \"A\", \"D\"]` | returns \"false\"; database state: `{\"A\": {\"C\": \"F\"}}` |\n",
    "\n",
    "Above table is just to show matching query and result one-by-one.\n",
    "\n",
    "Note: You will recieve a list of queries to the system:\n",
    "\n",
    "`queries = [\n",
    "[\"SET\", \"A\", \"B\", \"E\"],\n",
    "[\"SET\", \"A\", \"C\", \"F\"],\n",
    "[\"GET\", \"A\", \"B\"],\n",
    "[\"GET\", \"A\", \"D\"],\n",
    "[\"DELETE\", \"A\", \"B\"],\n",
    "[\"DELETE\", \"A\", \"D\"]\n",
    "]`\n",
    "\n",
    "And the final output should be `[\"\", \"\", \"E\", \"\", \"true\", \"false\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', 'E', '', 'true', 'false']\n",
      "[{'A': {'B': 'E'}}, {'A': {'B': 'E', 'C': 'F'}}, {'A': {'B': 'E', 'C': 'F'}}, {'A': {'B': 'E', 'C': 'F'}}, {'A': {'C': 'F'}}, {'A': {'C': 'F'}}]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "class MemDB:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "\n",
    "    def set(self, key, field, value):\n",
    "        if key not in self.data:\n",
    "            self.data[key] = {}\n",
    "        self.data[key][field] = value\n",
    "        return \"\"\n",
    "\n",
    "    def get(self, key, field):\n",
    "        if key in self.data:\n",
    "            return self.data[key].get(field, \"\")\n",
    "        return \"\"\n",
    "    \n",
    "    def delete(self, key, field):\n",
    "        if key in self.data and field in self.data[key]:\n",
    "            del self.data[key][field]\n",
    "            return \"true\"\n",
    "        return \"false\"\n",
    "    \n",
    "\n",
    "def solution(queries):\n",
    "    db = MemDB()\n",
    "    res = []\n",
    "    db_status = []\n",
    "    for query in queries:\n",
    "        if query[0] == \"SET\":\n",
    "            res.append(db.set(query[1], query[2], query[3]))\n",
    "        elif query[0] == \"GET\":\n",
    "            res.append(db.get(query[1], query[2]))\n",
    "        elif query[0] == \"DELETE\":\n",
    "            res.append(db.delete(query[1], query[2]))\n",
    "\n",
    "        db_status.append(copy.deepcopy(db.data))\n",
    "\n",
    "    return res, db_status\n",
    "\n",
    "queries = [\n",
    "    [\"SET\", \"A\", \"B\", \"E\"],\n",
    "    [\"SET\", \"A\", \"C\", \"F\"],\n",
    "    [\"GET\", \"A\", \"B\"],\n",
    "    [\"GET\", \"A\", \"D\"],\n",
    "    [\"DELETE\", \"A\", \"B\"],\n",
    "    [\"DELETE\", \"A\", \"D\"]\n",
    "]\n",
    "\n",
    "res, db_status = solution(queries)\n",
    "print(res)\n",
    "print(db_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 2\n",
    "\n",
    "The database should support displaying data based on filters. Introduce an operation to support\n",
    "printing some fields of a record.\n",
    "\n",
    "- `SCAN <key>` — should return a string representing the fields of a record associated with key.\n",
    "The returned string should be in the following format \"`<field1>(<value1>),\n",
    "<field2>(<value2>), ...`\", where fields are sorted lexicographically. If the specified record\n",
    "does not exist, returns an empty string.\n",
    "\n",
    "- `SCAN_BY_PREFIX <key> <prefix>` — should return a string representing some fields of a\n",
    "record associated with key. Specifically, only fields that start with prefix should be included.\n",
    "The returned string should be in the same format as in the SCAN operation with fields sorted\n",
    "in lexicographical order.\n",
    "\n",
    "Examples\n",
    "\n",
    "The example below shows how these operations should work (the section is scrollable to the right):\n",
    "\n",
    "| Queries | Explanations |\n",
    "|---------|--------------|\n",
    "| `[\"SET\", \"A\", \"BC\", \"E\"]` | returns `\"\"` <br>database state: `{\"A\": {\"BC\": \"E\"}}` |\n",
    "| `[\"SET\", \"A\", \"BD\", \"F\"]` | returns `\"\"` <br>database state: `{\"A\": {\"BC\": \"E\", \"BD\": \"F\"}}` |\n",
    "| `[\"SET\", \"A\", \"C\", \"G\"]` | returns `\"\"` <br>database state: `{\"A\": {\"BC\": \"E\", \"BD\": \"F\", \"C\": \"G\"}}` |\n",
    "| `[\"SCAN_BY_PREFIX\", \"A\", \"B\"]` | returns `\"BC(E), BD(F)\"` |\n",
    "| `[\"SCAN\", \"A\"]` | returns `\"BC(E), BD(F), C(G)\"` |\n",
    "| `[\"SCAN_BY_PREFIX\", \"B\", \"B\"]` | returns `\"\"` |\n",
    "\n",
    "\n",
    "\n",
    "Queries Explanations\n",
    "\n",
    "`queries = [\n",
    "    [\"SET\", \"A\", \"BC\", \"E\"],\n",
    "    [\"SET\", \"A\", \"BD\", \"F\"],\n",
    "    [\"SET\", \"A\", \"C\", \"G\"],\n",
    "    [\"SCAN_BY_PREFIX\", \"A\", \"B\"],\n",
    "    [\"SCAN\", \"A\"],\n",
    "    [\"SCAN_BY_PREFIX\", \"B\", \"B\"]\n",
    "]`\n",
    "\n",
    "the output should be `[\"\", \"\", \"\", \"BC(E), BD(F)\", \"BC(E), BD(F), C(G)\", \"\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', 'BC(E), BD(F)', 'BC(E), BD(F), C(G)', '']\n",
      "[{'A': {'BC': 'E'}}, {'A': {'BC': 'E', 'BD': 'F'}}, {'A': {'BC': 'E', 'BD': 'F', 'C': 'G'}}, {'A': {'BC': 'E', 'BD': 'F', 'C': 'G'}}, {'A': {'BC': 'E', 'BD': 'F', 'C': 'G'}}, {'A': {'BC': 'E', 'BD': 'F', 'C': 'G'}}]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "class MemDB:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "\n",
    "    def set(self, key, field, value):\n",
    "        if key not in self.data:\n",
    "            self.data[key] = {}\n",
    "        self.data[key][field] = value\n",
    "        return \"\"\n",
    "\n",
    "    def get(self, key, field):\n",
    "        if key in self.data:\n",
    "            return self.data[key].get(field, \"\")\n",
    "        return \"\"\n",
    "    \n",
    "    def delete(self, key, field):\n",
    "        if key in self.data and field in self.data[key]:\n",
    "            del self.data[key][field]\n",
    "            return \"true\"\n",
    "        return \"false\"\n",
    "    \n",
    "    def scan(self, key): \n",
    "        if key in self.data:\n",
    "            res = []\n",
    "            for field, value in self.data[key].items():\n",
    "                res.append(\"%s(%s)\" % (field, value))\n",
    "            return \", \".join(sorted(res))\n",
    "        return \"\"\n",
    "\n",
    "    def scan_by_prefix(self, key, prefix):\n",
    "        if key in self.data:\n",
    "            res = []\n",
    "            for field, value in self.data[key].items():\n",
    "                if field.startswith(prefix):\n",
    "                    res.append(\"%s(%s)\" % (field, value))\n",
    "            return \", \".join(sorted(res))\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "def solution(queries):\n",
    "    db = MemDB()\n",
    "    res = []\n",
    "    db_status = []\n",
    "    for query in queries:\n",
    "        if query[0] == \"SET\":\n",
    "            res.append(db.set(query[1], query[2], query[3]))\n",
    "        elif query[0] == \"GET\":\n",
    "            res.append(db.get(query[1], query[2]))\n",
    "        elif query[0] == \"DELETE\":\n",
    "            res.append(db.delete(query[1], query[2]))\n",
    "        elif query[0] == \"SCAN\":\n",
    "            res.append(db.scan(query[1]))\n",
    "        elif query[0] == \"SCAN_BY_PREFIX\":\n",
    "            res.append(db.scan_by_prefix(query[1], query[2]))\n",
    "\n",
    "        db_status.append(copy.deepcopy(db.data))\n",
    "\n",
    "    return res, db_status\n",
    "\n",
    "queries = [\n",
    "    [\"SET\", \"A\", \"BC\", \"E\"],\n",
    "    [\"SET\", \"A\", \"BD\", \"F\"],\n",
    "    [\"SET\", \"A\", \"C\", \"G\"],\n",
    "    [\"SCAN_BY_PREFIX\", \"A\", \"B\"],\n",
    "    [\"SCAN\", \"A\"],\n",
    "    [\"SCAN_BY_PREFIX\", \"B\", \"B\"]\n",
    "]\n",
    "\n",
    "res, db_status = solution(queries)\n",
    "print(res)\n",
    "print(db_status)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 3\n",
    "\n",
    "Support the timeline of operations and TTL (Time-To-Live) settings for records and fields. Each\n",
    "operation from previous levels now has an alternative version with a timestamp parameter to\n",
    "represent when the operation was executed. For each field-value pair in the database, the TTL\n",
    "determines how long that value will persist before being removed.\n",
    "\n",
    "Notes:\n",
    "- Time should always flow forward, so timestamps are guaranteed to strictly increase as\n",
    "operations are executed.\n",
    "\n",
    "- Each test cannot contain both versions of operations (with and without timestamp). However,\n",
    "you should maintain backward compatibility, so all previously defined methods should work\n",
    "in the same way as before.\n",
    "\n",
    "- `SET_AT <key> <field> <value> <timestamp>` — should insert a field-value pair or\n",
    "updates the value of the field in the record associated with key. This operation should\n",
    "return an empty string.\n",
    "\n",
    "- `SET_AT_WITH_TTL <key> <field> <value> <timestamp> <ttl>` — should insert a\n",
    "field-value pair or update the value of the field in the record associated with key. Also\n",
    "sets its Time-To-Live starting at timestamp to be ttl. The ttl is the amount of time that this\n",
    "field-value pair should exist in the database, meaning it will be available during this\n",
    "interval: `[timestamp, timestamp + ttl)`. This operation should return an empty string.\n",
    "\n",
    "- `DELETE_AT <key> <field> <timestamp>` — the same as DELETE, but with timestamp of the\n",
    "operation specified. Should return \"true\" if the field existed and was successfully deleted\n",
    "and \"false\" if the key didn't exist.\n",
    "\n",
    "- `GET_AT <key> <field> <timestamp>` — the same as GET, but with timestamp of the\n",
    "operation specified.\n",
    "\n",
    "- `SCAN_AT <key> <timestamp>` — the same as SCAN, but with timestamp of the operation\n",
    "specified.\n",
    "\n",
    "- `SCAN_BY_PREFIX_AT <key> <prefix> <timestamp>` — the same as SCAN_BY_PREFIX, but with\n",
    "timestamp of the operation specified.\n",
    "\n",
    "\n",
    "Examples 1:\n",
    "\n",
    "| Queries | Explanations |\n",
    "|---------|--------------|\n",
    "| `[\"SET_AT_WITH_TTL\", \"A\", \"BC\", \"E\", \"1\", \"9\"]` | returns `\"\"` <br>database state: `{\"A\": {\"BC\": \"E\"}}` <br>where `{\"BC\": \"E\"}` expires at timestamp 10 |\n",
    "| `[\"SET_AT_WITH_TTL\", \"A\", \"BC\", \"E\", \"5\", \"10\"]` | returns `\"\"` <br>database state: `{\"A\": {\"BC\": \"E\"}}` <br>as field \"BC\" in record \"A\" already exists, it was overwritten, and `{\"BC\": \"E\"}` now expires at timestamp 15 |\n",
    "| `[\"SET_AT\", \"A\", \"BD\", \"F\", \"5\"]` | returns `\"\"` <br>database state: `{\"A\": {\"BC\": \"E\", \"BD\": \"F\"}}` <br>where `{\"BD\": \"F\"}` does not expire |\n",
    "| `[\"SCAN_BY_PREFIX_AT\", \"A\", \"B\", \"14\"]` | returns `\"BC(E), BD(F)\"` |\n",
    "| `[\"SCAN_BY_PREFIX_AT\", \"A\", \"B\", \"15\"]` | returns `\"BD(F)\"` |\n",
    "\n",
    "Queries Explanation:\n",
    "\n",
    "`queries = [\n",
    "    [\"SET_AT_WITH_TTL\", \"A\", \"BC\", \"E\", \"1\", \"9\"],\n",
    "    [\"SET_AT_WITH_TTL\", \"A\", \"BC\", \"E\", \"5\", \"10\"],\n",
    "    [\"SET_AT\", \"A\", \"BD\", \"F\", \"5\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\", \"A\", \"B\", \"14\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\", \"A\", \"B\", \"15\"]\n",
    "]`\n",
    "\n",
    "the output should be `[\"\", \"\", \"\", \"BC(E), BD(F)\", \"BD(F)\"]` \n",
    "\n",
    "\n",
    "Examples 2:\n",
    "\n",
    "| Queries | Explanations |\n",
    "|---------|--------------|\n",
    "| `[\"SET_AT\", \"A\", \"B\", \"C\", \"1\"]` | returns `\"\"` <br>database state: `{\"A\": {\"B\": \"C\"}}` |\n",
    "| `[\"SET_AT_WITH_TTL\", \"X\", \"Y\", \"Z\", \"2\", \"15\"]` | returns `\"\"` <br>database state: `{\"X\": {\"Y\": \"Z\"}, \"A\": {\"B\": \"C\"}}` <br>where `{\"Y\": \"Z\"}` expires at timestamp 17 |\n",
    "| `[\"GET_AT\", \"X\", \"Y\", \"3\"]` | returns `\"Z\"` |\n",
    "| `[\"SET_AT_WITH_TTL\", \"A\", \"D\", \"E\", \"4\", \"10\"]` | returns `\"\"` <br>database state: `{\"X\": {\"Y\": \"Z\"}, \"A\": {\"D\": \"E\", \"B\": \"C\"}}` <br>where `{\"D\": \"E\"}` expires at timestamp 14 and `{\"Y\": \"Z\"}` expires at timestamp 17 |\n",
    "| `[\"SCAN_AT\", \"A\", \"13\"]` | returns `\"B(C), D(E)\"` |\n",
    "| `[\"SCAN_AT\", \"X\", \"16\"]` | returns `\"Y(Z)\"` |\n",
    "| `[\"SCAN_AT\", \"X\", \"17\"]` | returns `\"\"`<br>Note that all fields in record \"X\" have expired |\n",
    "| `[\"DELETE_AT\", \"X\", \"Y\", \"20\"]` | returns `\"false\"`<br>the record \"X\" was expired at timestamp 17 and can't be deleted |\n",
    "\n",
    "\n",
    "Queries Explanation:\n",
    "`queries = [\n",
    "[\"SET_AT\", \"A\", \"B\", \"C\",\n",
    "\"1\"],\n",
    "[\"SET_AT_WITH_TTL\", \"X\",\n",
    "\"Y\", \"Z\", \"2\", \"15\"],\n",
    "[\"GET_AT\", \"X\", \"Y\", \"3\"],\n",
    "[\"SET_AT_WITH_TTL\", \"A\",\n",
    "\"D\", \"E\", \"4\", \"10\"],\n",
    "[\"SCAN_AT\", \"A\", \"13\"],\n",
    "[\"SCAN_AT\", \"X\", \"16\"],\n",
    "[\"SCAN_AT\", \"X\", \"17\"],\n",
    "[\"DELETE_AT\", \"X\", \"Y\",\n",
    "\"20\"]\n",
    "]`\n",
    "\n",
    "the output should be [\"\", \"\", \"Z\", \"\", \"B(C), D(E)\", \"Y(Z)\", \"\", \"false\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', 'BC(E), BD(F)', 'BD(F)']\n",
      "[{'A': {'BC': ('E', 1.0, 9.0)}}, {'A': {'BC': ('E', 5.0, 10.0)}}, {'A': {'BC': ('E', 5.0, 10.0), 'BD': ('F', 5.0, inf)}}, {'A': {'BC': ('E', 5.0, 10.0), 'BD': ('F', 5.0, inf)}}, {'A': {'BC': ('E', 5.0, 10.0), 'BD': ('F', 5.0, inf)}}]\n",
      "['', '', 'Z', '', 'B(C), D(E)', 'Y(Z)', '', 'false']\n",
      "[{'A': {'B': ('C', 1.0, inf)}}, {'A': {'B': ('C', 1.0, inf)}, 'X': {'Y': ('Z', 2.0, 15.0)}}, {'A': {'B': ('C', 1.0, inf)}, 'X': {'Y': ('Z', 2.0, 15.0)}}, {'A': {'B': ('C', 1.0, inf), 'D': ('E', 4.0, 10.0)}, 'X': {'Y': ('Z', 2.0, 15.0)}}, {'A': {'B': ('C', 1.0, inf), 'D': ('E', 4.0, 10.0)}, 'X': {'Y': ('Z', 2.0, 15.0)}}, {'A': {'B': ('C', 1.0, inf), 'D': ('E', 4.0, 10.0)}, 'X': {'Y': ('Z', 2.0, 15.0)}}, {'A': {'B': ('C', 1.0, inf), 'D': ('E', 4.0, 10.0)}, 'X': {'Y': ('Z', 2.0, 15.0)}}, {'A': {'B': ('C', 1.0, inf), 'D': ('E', 4.0, 10.0)}, 'X': {'Y': ('Z', 2.0, 15.0)}}]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "class MemDB:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "        self.data_ts = {}\n",
    "\n",
    "    def set(self, key, field, value):\n",
    "        if key not in self.data:\n",
    "            self.data[key] = {}\n",
    "        self.data[key][field] = value\n",
    "        return \"\"\n",
    "\n",
    "    def get(self, key, field):\n",
    "        if key in self.data:\n",
    "            return self.data[key].get(field, \"\")\n",
    "        return \"\"\n",
    "    \n",
    "    def delete(self, key, field):\n",
    "        if key in self.data and field in self.data[key]:\n",
    "            del self.data[key][field]\n",
    "            return \"true\"\n",
    "        return \"false\"\n",
    "    \n",
    "    def scan(self, key): \n",
    "        if key in self.data:\n",
    "            res = []\n",
    "            for field, value in self.data[key].items():\n",
    "                res.append(\"%s(%s)\" % (field, value))\n",
    "            return \", \".join(sorted(res))\n",
    "        return \"\"\n",
    "\n",
    "    def scan_by_prefix(self, key, prefix):\n",
    "        if key in self.data:\n",
    "            res = []\n",
    "            for field, value in self.data[key].items():\n",
    "                if field.startswith(prefix):\n",
    "                    res.append(\"%s(%s)\" % (field, value))\n",
    "            return \", \".join(sorted(res))\n",
    "        return \"\"\n",
    "    \n",
    "    def set_at(self, key, field, value, timestamp:float):\n",
    "        if key not in self.data_ts:\n",
    "            self.data_ts[key] = {}\n",
    "\n",
    "        self.data_ts[key][field] = (value, timestamp, float('inf'))\n",
    "        return \"\"\n",
    "\n",
    "    def set_at_with_ttl(self, key, field, value, timestamp:float, ttl:float):\n",
    "        if key not in self.data_ts:\n",
    "            self.data_ts[key] = {}\n",
    "        \n",
    "        self.data_ts[key][field] = (value, timestamp, ttl)\n",
    "        return \"\"\n",
    "\n",
    "    def delete_at(self, key, field, timestamp:float):\n",
    "        if key in self.data_ts and field in self.data_ts[key]:\n",
    "            _, ts, ttl = self.data_ts[key][field]\n",
    "            if ts <= timestamp < ts + ttl:\n",
    "                del self.data_ts[key][field]\n",
    "                return \"true\"\n",
    "        \n",
    "        return \"false\"\n",
    "\n",
    "    def get_at(self, key, field, timestamp:float):\n",
    "        if key in self.data_ts and field in self.data_ts[key]:\n",
    "            value, ts, ttl = self.data_ts[key][field]\n",
    "            if ts <= timestamp < ts + ttl:\n",
    "                return value\n",
    "        return \"\"\n",
    "\n",
    "    def scan_at(self, key, timestamp:float):\n",
    "        if key in self.data_ts:\n",
    "            res = []\n",
    "            for field, (value, ts, ttl) in self.data_ts[key].items():\n",
    "                if ts <= timestamp < ts + ttl:\n",
    "                    res.append(\"%s(%s)\" % (field, value))\n",
    "            return \", \".join(sorted(res))\n",
    "        \n",
    "        return \"\"\n",
    "\n",
    "    def scan_by_prefix_at(self, key, prefix, timestamp:float):\n",
    "        if key in self.data_ts:\n",
    "            res = []\n",
    "            for field, (value, ts, ttl) in self.data_ts[key].items():\n",
    "                if ts <= timestamp < ts + ttl and field.startswith(prefix):\n",
    "                    res.append(\"%s(%s)\" % (field, value))\n",
    "            return \", \".join(sorted(res))\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def solution(queries):\n",
    "    db = MemDB()\n",
    "    res = []\n",
    "    db_ts_status = []\n",
    "    for query in queries:\n",
    "        if query[0] == \"SET\":\n",
    "            res.append(db.set(query[1], query[2], query[3]))\n",
    "        elif query[0] == \"GET\":\n",
    "            res.append(db.get(query[1], query[2]))\n",
    "        elif query[0] == \"DELETE\":\n",
    "            res.append(db.delete(query[1], query[2]))\n",
    "        elif query[0] == \"SCAN\":\n",
    "            res.append(db.scan(query[1]))\n",
    "        elif query[0] == \"SCAN_BY_PREFIX\":\n",
    "            res.append(db.scan_by_prefix(query[1], query[2]))\n",
    "        elif query[0] == \"SET_AT\":\n",
    "            res.append(db.set_at(query[1], query[2], query[3], float(query[4])))\n",
    "        elif query[0] == \"SET_AT_WITH_TTL\":\n",
    "            res.append(db.set_at_with_ttl(query[1], query[2], query[3], float(query[4]), float(query[5])))\n",
    "        elif query[0] == \"GET_AT\":\n",
    "            res.append(db.get_at(query[1], query[2], float(query[3])))\n",
    "        elif query[0] == \"DELETE_AT\":\n",
    "            res.append(db.delete_at(query[1], query[2], float(query[3])))\n",
    "        elif query[0] == \"SCAN_AT\":\n",
    "            res.append(db.scan_at(query[1], float(query[2])))\n",
    "        elif query[0] == \"SCAN_BY_PREFIX_AT\":\n",
    "            res.append(db.scan_by_prefix_at(query[1], query[2], float(query[3])))\n",
    "\n",
    "        db_ts_status.append(copy.deepcopy(db.data_ts))\n",
    "\n",
    "    return res, db_ts_status\n",
    "\n",
    "queries_1 = [\n",
    "    [\"SET_AT_WITH_TTL\", \"A\", \"BC\", \"E\", \"1\", \"9\"],\n",
    "    [\"SET_AT_WITH_TTL\", \"A\", \"BC\", \"E\", \"5\", \"10\"],\n",
    "    [\"SET_AT\", \"A\", \"BD\", \"F\", \"5\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\", \"A\", \"B\", \"14\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\", \"A\", \"B\", \"15\"]\n",
    "]\n",
    "\n",
    "res_1, db_ts_status_1 = solution(queries_1)\n",
    "print(res_1)\n",
    "print(db_ts_status_1)\n",
    "\n",
    "queries_2 = [\n",
    "    [\"SET_AT\", \"A\", \"B\", \"C\",\"1\"],\n",
    "    [\"SET_AT_WITH_TTL\", \"X\", \"Y\", \"Z\", \"2\", \"15\"],\n",
    "    [\"GET_AT\", \"X\", \"Y\", \"3\"],\n",
    "    [\"SET_AT_WITH_TTL\", \"A\", \"D\", \"E\", \"4\", \"10\"],\n",
    "    [\"SCAN_AT\", \"A\", \"13\"],\n",
    "    [\"SCAN_AT\", \"X\", \"16\"],\n",
    "    [\"SCAN_AT\", \"X\", \"17\"],\n",
    "    [\"DELETE_AT\", \"X\", \"Y\", \"20\"]\n",
    "]\n",
    "\n",
    "res_2, db_ts_status_2 = solution(queries_2)\n",
    "print(res_2)\n",
    "print(db_ts_status_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level 4\n",
    "\n",
    "The database should be backed up from time to time. Introduce operations to support backing up\n",
    "and restoring the database state based on timestamps. When restoring, ttl expiration times should\n",
    "be recalculated accordingly.\n",
    "\n",
    "- `BACKUP <timestamp>` — should save the database state at the specified timestamp, including\n",
    "the remaining ttl for all records and fields. Remaining ttl is the difference between their\n",
    "initial ttl and their current lifespan (the duration between the timestamp of this operation\n",
    "and their initial timestamp). Returns a string representing the number of non-empty\n",
    "non-expired records in the database.\n",
    "\n",
    "- `RESTORE <timestamp> <timestampToRestore>` — should restore the database from the latest\n",
    "backup before or at timestampToRestore. It's guaranteed that a backup before or at\n",
    "timestampToRestore will exist. Expiration times for restored records and fields should be\n",
    "recalculated according to the timestamp of this operation - since the database timeline\n",
    "always flows forward, restored records and fields should expire after the timestamp of this\n",
    "operation, depending on their remaining ttls at backup. This operation should return an\n",
    "empty string.\n",
    "\n",
    "Examples\n",
    "\n",
    "| Query | Result/Database State |\n",
    "|-------|---------------------|\n",
    "| `[\"SET_AT_WITH_TTL\", \"A\", \"B\", \"C\", \"1\", \"10\"]` | `\"\"` ; Database: `{\"A\": {\"B\": \"C\"}}` with lifespan `[1, 11)` |\n",
    "| `[\"BACKUP\", \"3\"]` | `\"1\"` ; Saves database state |\n",
    "| `[\"SET_AT\", \"A\", \"D\", \"E\", \"4\"]` | `\"\"` ; Database: `{\"A\": {\"D\": \"E\", \"B\": \"C\"}}` |\n",
    "| `[\"BACKUP\", \"5\"]` | `\"1\"` ; Saves database state |\n",
    "| `[\"DELETE_AT\", \"A\", \"B\", \"8\"]` | `\"true\"` ; Database: `{\"A\": {\"D\": \"E\"}}` |\n",
    "| `[\"BACKUP\", \"9\"]` | `\"1\"` ; Saves database state |\n",
    "| `[\"RESTORE\", \"10\", \"7\"]` | `\"\"` ; Restores to state: `{\"A\": {\"D\": \"E\", \"B\": \"C\"}}` with `{\"B\": \"C\"}` expiring at t=16 |\n",
    "| `[\"BACKUP\", \"11\"]` | `\"1\"` ; Saves database state |\n",
    "| `[\"SCAN_AT\", \"A\", \"15\"]` | `\"B(C), D(E)\"` |\n",
    "| `[\"SCAN_AT\", \"A\", \"16\"]` | `\"D(E)\"` |\n",
    "\n",
    "\n",
    "Query Explanation:\n",
    "\n",
    "`queries = [\n",
    "    [\"SET_AT_WITH_TTL\", \"A\", \"B\", \"C\", \"1\", \"10\"],\n",
    "    [\"BACKUP\", \"3\"],\n",
    "    [\"SET_AT\", \"A\", \"D\", \"E\", \"4\"],\n",
    "    [\"BACKUP\", \"5\"],\n",
    "    [\"DELETE_AT\", \"A\", \"B\", \"8\"],\n",
    "    [\"BACKUP\", \"9\"],\n",
    "    [\"RESTORE\", \"10\", \"7\"],\n",
    "    [\"BACKUP\", \"11\"],\n",
    "    [\"SCAN_AT\", \"A\", \"15\"],\n",
    "    [\"SCAN_AT\", \"A\", \"16\"]\n",
    "]`\n",
    "\n",
    "The output should be `[\"\", \"1\", \"\", \"1\", \"true\", \"1\", \"\", \"1\", \"B(C), D(E)\", \"D(E)\"]`.\n",
    "\n",
    "More queries examples:\n",
    "\n",
    "`queries = [\n",
    "    [\"BACKUP\",\"160000000\"],\n",
    "    [\"RESTORE\",\"160000001\",\"160000000\"],\n",
    "    [\"SET_AT_WITH_TTL\",\"key\",\"field\",\"str\",\"160000100\",\"200\"],\n",
    "    [\"BACKUP\",\"160000200\"],\n",
    "    [\"RESTORE\",\"160000250\",\"160000000\"],\n",
    "    [\"GET_AT\",\"key\",\"field\",\"160000300\"],\n",
    "    [\"BACKUP\",\"160000350\"],\n",
    "    [\"RESTORE\",\"160000400\",\"160000200\"],\n",
    "    [\"GET_AT\",\"key\",\"field\",\"160000450\"],\n",
    "    [\"GET_AT\",\"key\",\"field\",\"160000500\"]\n",
    "]`\n",
    "\n",
    "`queries = [\n",
    "    [\"SET_AT\",\"foo\",\"bar\",\"baz\",\"160000100\"],\n",
    "    [\"SET_AT_WITH_TTL\",\"key\",\"key\",\"value\",\"160000120\",\"1880\"],\n",
    "    [\"SET_AT_WITH_TTL\",\"key\",\"key\",\"value\",\"160000170\",\"680\"],\n",
    "    [\"SET_AT_WITH_TTL\",\"bar\",\"baz\",\"foo\",\"160000200\",\"100\"],\n",
    "    [\"BACKUP\",\"160000250\"],\n",
    "    [\"BACKUP\",\"160000270\"],\n",
    "    [\"SET_AT_WITH_TTL\",\"boo\",\"text1\",\"text2\",\"160000300\",\"900\"],\n",
    "    [\"BACKUP\",\"160000850\"],\n",
    "    [\"GET_AT\",\"foo\",\"bar\",\"160000900\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\",\"key\",\"k\",\"160000920\"],\n",
    "    [\"DELETE_AT\",\"foo\",\"bar\",\"160000950\"],\n",
    "    [\"DELETE_AT\",\"key\",\"key\",\"160000960\"],\n",
    "    [\"RESTORE\",\"160000970\",\"160000250\"],\n",
    "    [\"SCAN_AT\",\"key\",\"160000980\"],\n",
    "    [\"SCAN_AT\",\"key\",\"160001021\"],\n",
    "    [\"RESTORE\",\"160001030\",\"160000850\"],\n",
    "    [\"SCAN_AT\",\"key\",\"160001040\"],\n",
    "    [\"SCAN_AT\",\"boo\",\"160001041\"],\n",
    "    [\"SCAN_AT\",\"bar\",\"160001042\"]\n",
    "]`\n",
    "\n",
    "`queries = [\n",
    "    [\"DELETE_AT\",\"key\",\"key\",\"160000010\"],\n",
    "    [\"DELETE_AT\",\"key\",\"key2\",\"160000020\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\",\"key\",\"key\",\"160000025\"],\n",
    "    [\"GET_AT\",\"A\",\"B\",\"160000030\"],\n",
    "    [\"GET_AT\",\"key\",\"key\",\"160000040\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\",\"key\",\"key\",\"160000050\"],\n",
    "    [\"DELETE_AT\",\"key\",\"key\",\"160000052\"],\n",
    "    [\"BACKUP\",\"160000055\"],\n",
    "    [\"SET_AT_WITH_TTL\",\"key\",\"key\",\"aaaaa\",\"160000060\",\"1940\"],\n",
    "    [\"SET_AT_WITH_TTL\",\"foo\",\"bar\",\"baz\",\"160000070\",\"101\"],\n",
    "    [\"DELETE_AT\",\"key\",\"bar\",\"160000080\"],\n",
    "    [\"DELETE_AT\",\"key\",\"key2\",\"160000090\"],\n",
    "    [\"BACKUP\",\"160000100\"],\n",
    "    [\"SET_AT_WITH_TTL\",\"key\",\"key\",\"otherValue\",\"160000120\",\"20\"],\n",
    "    [\"RESTORE\",\"160000130\",\"160000099\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\",\"key\",\"key\",\"160000150\"],\n",
    "    [\"RESTORE\",\"160000160\",\"160000100\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\",\"key\",\"k\",\"160000200\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\",\"key\",\"k\",\"160000201\"],\n",
    "    [\"RESTORE\",\"160000250\",\"160000110\"],\n",
    "    [\"SCAN_AT\",\"key\",\"160000270\"],\n",
    "    [\"SCAN_BY_PREFIX_AT\",\"key\",\"key\",\"160000350\"]\n",
    "]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '1', '', '1', 'true', '1', '', '1', 'B(C), D(E)', 'D(E)']\n",
      "Query 1: ['SET_AT_WITH_TTL', 'A', 'B', 'C', '1', '10']\n",
      "return value: \n",
      "data_ts: {'A': {'B': ('C', 1.0, 10.0)}}\n",
      "backup_data: {}\n",
      "Query 2: ['BACKUP', '3']\n",
      "return value: 1\n",
      "data_ts: {'A': {'B': ('C', 3.0, 8.0)}}\n",
      "backup_data: {3.0: {'A': {'B': ('C', 3.0, 8.0)}}}\n",
      "Query 3: ['SET_AT', 'A', 'D', 'E', '4']\n",
      "return value: \n",
      "data_ts: {'A': {'B': ('C', 3.0, 8.0), 'D': ('E', 4.0, inf)}}\n",
      "backup_data: {3.0: {'A': {'B': ('C', 3.0, 8.0)}}}\n",
      "Query 4: ['BACKUP', '5']\n",
      "return value: 1\n",
      "data_ts: {'A': {'B': ('C', 5.0, 6.0), 'D': ('E', 4.0, inf)}}\n",
      "backup_data: {3.0: {'A': {'B': ('C', 3.0, 8.0)}}, 5.0: {'A': {'B': ('C', 5.0, 6.0), 'D': ('E', 4.0, inf)}}}\n",
      "Query 5: ['DELETE_AT', 'A', 'B', '8']\n",
      "return value: true\n",
      "data_ts: {'A': {'D': ('E', 4.0, inf)}}\n",
      "backup_data: {3.0: {'A': {'B': ('C', 3.0, 8.0)}}, 5.0: {'A': {'B': ('C', 5.0, 6.0), 'D': ('E', 4.0, inf)}}}\n",
      "Query 6: ['BACKUP', '9']\n",
      "return value: 1\n",
      "data_ts: {'A': {'D': ('E', 4.0, inf)}}\n",
      "backup_data: {3.0: {'A': {'B': ('C', 3.0, 8.0)}}, 5.0: {'A': {'B': ('C', 5.0, 6.0), 'D': ('E', 4.0, inf)}}, 9.0: {'A': {'D': ('E', 4.0, inf)}}}\n",
      "Query 7: ['RESTORE', '10', '7']\n",
      "return value: \n",
      "data_ts: {'A': {'B': ('C', 10.0, 6.0), 'D': ('E', 10.0, inf)}}\n",
      "backup_data: {3.0: {'A': {'B': ('C', 3.0, 8.0)}}, 5.0: {'A': {'B': ('C', 5.0, 6.0), 'D': ('E', 4.0, inf)}}, 9.0: {'A': {'D': ('E', 4.0, inf)}}}\n",
      "Query 8: ['BACKUP', '11']\n",
      "return value: 1\n",
      "data_ts: {'A': {'B': ('C', 11.0, 5.0), 'D': ('E', 10.0, inf)}}\n",
      "backup_data: {3.0: {'A': {'B': ('C', 3.0, 8.0)}}, 5.0: {'A': {'B': ('C', 5.0, 6.0), 'D': ('E', 4.0, inf)}}, 9.0: {'A': {'D': ('E', 4.0, inf)}}, 11.0: {'A': {'B': ('C', 11.0, 5.0), 'D': ('E', 10.0, inf)}}}\n",
      "Query 9: ['SCAN_AT', 'A', '15']\n",
      "return value: B(C), D(E)\n",
      "data_ts: {'A': {'B': ('C', 11.0, 5.0), 'D': ('E', 10.0, inf)}}\n",
      "backup_data: {3.0: {'A': {'B': ('C', 3.0, 8.0)}}, 5.0: {'A': {'B': ('C', 5.0, 6.0), 'D': ('E', 4.0, inf)}}, 9.0: {'A': {'D': ('E', 4.0, inf)}}, 11.0: {'A': {'B': ('C', 11.0, 5.0), 'D': ('E', 10.0, inf)}}}\n",
      "Query 10: ['SCAN_AT', 'A', '16']\n",
      "return value: D(E)\n",
      "data_ts: {'A': {'B': ('C', 11.0, 5.0), 'D': ('E', 10.0, inf)}}\n",
      "backup_data: {3.0: {'A': {'B': ('C', 3.0, 8.0)}}, 5.0: {'A': {'B': ('C', 5.0, 6.0), 'D': ('E', 4.0, inf)}}, 9.0: {'A': {'D': ('E', 4.0, inf)}}, 11.0: {'A': {'B': ('C', 11.0, 5.0), 'D': ('E', 10.0, inf)}}}\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "class MemDB:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "        self.data_ts = {}\n",
    "        self.backup_data = {}\n",
    "\n",
    "    def set(self, key, field, value):\n",
    "        if key not in self.data:\n",
    "            self.data[key] = {}\n",
    "        self.data[key][field] = value\n",
    "        return \"\"\n",
    "\n",
    "    def get(self, key, field):\n",
    "        if key in self.data:\n",
    "            return self.data[key].get(field, \"\")\n",
    "        return \"\"\n",
    "    \n",
    "    def delete(self, key, field):\n",
    "        if key in self.data and field in self.data[key]:\n",
    "            del self.data[key][field]\n",
    "            return \"true\"\n",
    "        return \"false\"\n",
    "    \n",
    "    def scan(self, key): \n",
    "        if key in self.data:\n",
    "            res = []\n",
    "            for field, value in self.data[key].items():\n",
    "                res.append(\"%s(%s)\" % (field, value))\n",
    "            return \", \".join(sorted(res))\n",
    "        return \"\"\n",
    "\n",
    "    def scan_by_prefix(self, key, prefix):\n",
    "        if key in self.data:\n",
    "            res = []\n",
    "            for field, value in self.data[key].items():\n",
    "                if field.startswith(prefix):\n",
    "                    res.append(\"%s(%s)\" % (field, value))\n",
    "            return \", \".join(sorted(res))\n",
    "        return \"\"\n",
    "    \n",
    "    def set_at(self, key, field, value, timestamp:float):\n",
    "        if key not in self.data_ts:\n",
    "            self.data_ts[key] = {}\n",
    "\n",
    "        self.data_ts[key][field] = (value, timestamp, float('inf'))\n",
    "        return \"\"\n",
    "\n",
    "    def set_at_with_ttl(self, key, field, value, timestamp:float, ttl:float):\n",
    "        if key not in self.data_ts:\n",
    "            self.data_ts[key] = {}\n",
    "        \n",
    "        self.data_ts[key][field] = (value, timestamp, ttl)\n",
    "        return \"\"\n",
    "\n",
    "    def delete_at(self, key, field, timestamp:float):\n",
    "        if key in self.data_ts and field in self.data_ts[key]:\n",
    "            _, ts, ttl = self.data_ts[key][field]\n",
    "            if ts <= timestamp < ts + ttl:\n",
    "                del self.data_ts[key][field]\n",
    "                return \"true\"\n",
    "        \n",
    "        return \"false\"\n",
    "\n",
    "    def get_at(self, key, field, timestamp:float):\n",
    "        if key in self.data_ts and field in self.data_ts[key]:\n",
    "            value, ts, ttl = self.data_ts[key][field]\n",
    "            if ts <= timestamp < ts + ttl:\n",
    "                return value\n",
    "        return \"\"\n",
    "\n",
    "    def scan_at(self, key, timestamp:float):\n",
    "        if key in self.data_ts:\n",
    "            res = []\n",
    "            for field, (value, ts, ttl) in self.data_ts[key].items():\n",
    "                if ts <= timestamp < ts + ttl:\n",
    "                    res.append(\"%s(%s)\" % (field, value))\n",
    "            return \", \".join(sorted(res))\n",
    "        \n",
    "        return \"\"\n",
    "\n",
    "    def scan_by_prefix_at(self, key, prefix, timestamp:float):\n",
    "        if key in self.data_ts:\n",
    "            res = []\n",
    "            for field, (value, ts, ttl) in self.data_ts[key].items():\n",
    "                if ts <= timestamp < ts + ttl and field.startswith(prefix):\n",
    "                    res.append(\"%s(%s)\" % (field, value))\n",
    "            return \", \".join(sorted(res))\n",
    "        return \"\"\n",
    "    \n",
    "    def backup(self, timestamp:float):\n",
    "        count = 0 # number of non-empty key records\n",
    "        for key in self.data_ts.keys():\n",
    "            non_empty_flag = False\n",
    "            for field, (value, ts, ttl) in self.data_ts[key].items():\n",
    "                if ttl != float('inf'):\n",
    "                    lifespan = ts + ttl - timestamp\n",
    "                    if lifespan > 0:\n",
    "                        # update the timestamp, ttl to current timestamp and current lifespan\n",
    "                        self.data_ts[key][field] = (value, timestamp, lifespan)\n",
    "                        non_empty_flag = True\n",
    "                else:\n",
    "                    non_empty_flag = True\n",
    "    \n",
    "            if non_empty_flag:\n",
    "                count += 1\n",
    "\n",
    "        self.backup_data[timestamp] = copy.deepcopy(self.data_ts)\n",
    "        return str(count)\n",
    "  \n",
    "\n",
    "    def restore(self, timestamp:float, timestampToRestore:float):\n",
    "        backup_timestamps = sorted(self.backup_data.keys())\n",
    "\n",
    "        backup_ts_to_restore = backup_timestamps[0]        \n",
    "        for ts in backup_timestamps:\n",
    "            if ts <= timestampToRestore:\n",
    "                backup_ts_to_restore = ts\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        self.data_ts = copy.deepcopy(self.backup_data[backup_ts_to_restore])\n",
    "\n",
    "        for key in self.data_ts.keys():\n",
    "            for field, (value, ts, ttl) in self.data_ts[key].items():\n",
    "                self.data_ts[key][field] = (value, timestamp, ttl)\n",
    "                \n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def solution(queries):\n",
    "    db = MemDB()\n",
    "    res = []\n",
    "    db_ts_status = []\n",
    "    db_backup_status = []\n",
    "    for query in queries:\n",
    "        if query[0] == \"SET\":\n",
    "            res.append(db.set(query[1], query[2], query[3]))\n",
    "        elif query[0] == \"GET\":\n",
    "            res.append(db.get(query[1], query[2]))\n",
    "        elif query[0] == \"DELETE\":\n",
    "            res.append(db.delete(query[1], query[2]))\n",
    "        elif query[0] == \"SCAN\":\n",
    "            res.append(db.scan(query[1]))\n",
    "        elif query[0] == \"SCAN_BY_PREFIX\":\n",
    "            res.append(db.scan_by_prefix(query[1], query[2]))\n",
    "        elif query[0] == \"SET_AT\":\n",
    "            res.append(db.set_at(query[1], query[2], query[3], float(query[4])))\n",
    "        elif query[0] == \"SET_AT_WITH_TTL\":\n",
    "            res.append(db.set_at_with_ttl(query[1], query[2], query[3], float(query[4]), float(query[5])))\n",
    "        elif query[0] == \"GET_AT\":\n",
    "            res.append(db.get_at(query[1], query[2], float(query[3])))\n",
    "        elif query[0] == \"DELETE_AT\":\n",
    "            res.append(db.delete_at(query[1], query[2], float(query[3])))\n",
    "        elif query[0] == \"SCAN_AT\":\n",
    "            res.append(db.scan_at(query[1], float(query[2])))\n",
    "        elif query[0] == \"SCAN_BY_PREFIX_AT\":\n",
    "            res.append(db.scan_by_prefix_at(query[1], query[2], float(query[3])))\n",
    "        elif query[0] == \"BACKUP\":\n",
    "            res.append(db.backup(float(query[1])))\n",
    "        elif query[0] == \"RESTORE\":\n",
    "            res.append(db.restore(float(query[1]), float(query[2])))\n",
    "\n",
    "        db_ts_status.append(copy.deepcopy(db.data_ts))\n",
    "        db_backup_status.append(copy.deepcopy(db.backup_data))\n",
    "\n",
    "    return res, db_ts_status, db_backup_status\n",
    "\n",
    "queries_1 = [\n",
    "    [\"SET_AT_WITH_TTL\", \"A\", \"B\", \"C\", \"1\", \"10\"],\n",
    "    [\"BACKUP\", \"3\"],\n",
    "    [\"SET_AT\", \"A\", \"D\", \"E\", \"4\"],\n",
    "    [\"BACKUP\", \"5\"],\n",
    "    [\"DELETE_AT\", \"A\", \"B\", \"8\"],\n",
    "    [\"BACKUP\", \"9\"],\n",
    "    [\"RESTORE\", \"10\", \"7\"],\n",
    "    [\"BACKUP\", \"11\"],\n",
    "    [\"SCAN_AT\", \"A\", \"15\"],\n",
    "    [\"SCAN_AT\", \"A\", \"16\"]\n",
    "]\n",
    "\n",
    "res_1, db_ts_status_1, db_backup_status_1 = solution(queries_1)\n",
    "\n",
    "print(res_1)\n",
    "for i, (return_value, data_ts, backup_data) in enumerate(zip(res_1, db_ts_status_1, db_backup_status_1)):\n",
    "    print(f\"Query {i+1}: {queries_1[i]}\")\n",
    "    print(f\"return value: {return_value}\")\n",
    "    print(f\"data_ts: {data_ts}\")\n",
    "    print(f\"backup_data: {backup_data}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
